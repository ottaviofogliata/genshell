<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "https://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en-US">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=11"/>
<meta name="generator" content="Doxygen 1.14.0"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>GenShell: gemma_llama.h File Reference</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<script type="text/javascript" src="clipboard.js"></script>
<link href="navtree.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="navtreedata.js"></script>
<script type="text/javascript" src="navtree.js"></script>
<script type="text/javascript" src="cookie.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr id="projectrow">
  <td id="projectalign">
   <div id="projectname">GenShell
   </div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.14.0 -->
<script type="text/javascript">
var searchBox = new SearchBox("searchBox", "search/",'.html');
</script>
<script type="text/javascript">
$(function() { codefold.init(); });
</script>
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
$(function() {
  initMenu('',true,false,'search.php','Search',true);
  $(function() { init_search(); });
});
</script>
<div id="main-nav"></div>
</div><!-- top -->
<div id="side-nav" class="ui-resizable side-nav-resizable">
  <div id="nav-tree">
    <div id="nav-tree-contents">
      <div id="nav-sync" class="sync"></div>
    </div>
  </div>
  <div id="splitbar" style="-moz-user-select:none;" 
       class="ui-resizable-handle">
  </div>
</div>
<script type="text/javascript">
$(function(){initNavTree('gemma__llama_8h.html','',''); });
</script>
<div id="container">
<div id="doc-content">
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<div id="MSearchResults">
<div class="SRPage">
<div id="SRIndex">
<div id="SRResults"></div>
<div class="SRStatus" id="Loading">Loading...</div>
<div class="SRStatus" id="Searching">Searching...</div>
<div class="SRStatus" id="NoMatches">No Matches</div>
</div>
</div>
</div>
</div>

<div class="header">
  <div class="headertitle"><div class="title">gemma_llama.h File Reference</div></div>
</div><!--header-->
<div class="contents">
<div class="textblock"><code>#include &lt;stddef.h&gt;</code><br />
<code>#include &lt;stdint.h&gt;</code><br />
</div><div class="textblock"><div id="dynsection-0" onclick="return dynsection.toggleVisibility(this)" class="dynheader closed" style="cursor:pointer;"><span class="dynarrow"><span class="arrowhead closed"></span></span>Include dependency graph for gemma_llama.h:</div>
<div id="dynsection-0-summary" class="dynsummary" style="display:block;">
</div>
<div id="dynsection-0-content" class="dyncontent" style="display:none;">
<div class="center"><iframe scrolling="no" loading="lazy" frameborder="0" src="gemma__llama_8h__incl.svg" width="168" height="111"><p><b>This browser is not able to show SVG: try Firefox, Chrome, Safari, or Opera instead.</b></p></iframe></div>
</div>
</div><div class="textblock"><div id="dynsection-1" onclick="return dynsection.toggleVisibility(this)" class="dynheader closed" style="cursor:pointer;"><span class="dynarrow"><span class="arrowhead closed"></span></span>This graph shows which files directly or indirectly include this file:</div>
<div id="dynsection-1-summary" class="dynsummary" style="display:block;">
</div>
<div id="dynsection-1-content" class="dyncontent" style="display:none;">
<div class="center"><iframe scrolling="no" loading="lazy" frameborder="0" src="gemma__llama_8h__dep__incl.svg" width="259" height="111"><p><b>This browser is not able to show SVG: try Firefox, Chrome, Safari, or Opera instead.</b></p></iframe></div>
</div>
</div>
<p><a href="gemma__llama_8h_source.html">Go to the source code of this file.</a></p>
<table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 id="header-nested-classes" class="groupheader"><a id="nested-classes" name="nested-classes"></a>
Classes</h2></td></tr>
<tr class="memitem:gemma_5Fruntime_5Fconfig" id="r_gemma_5Fruntime_5Fconfig"><td class="memItemLeft" align="right" valign="top">struct &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="structgemma__runtime__config.html">gemma_runtime_config</a></td></tr>
<tr class="memitem:gemma_5Flogit_5Fbias_5Fentry" id="r_gemma_5Flogit_5Fbias_5Fentry"><td class="memItemLeft" align="right" valign="top">struct &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="structgemma__logit__bias__entry.html">gemma_logit_bias_entry</a></td></tr>
<tr class="memitem:gemma_5Fsampling_5Fconfig" id="r_gemma_5Fsampling_5Fconfig"><td class="memItemLeft" align="right" valign="top">struct &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="structgemma__sampling__config.html">gemma_sampling_config</a></td></tr>
</table><table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 id="header-typedef-members" class="groupheader"><a id="typedef-members" name="typedef-members"></a>
Typedefs</h2></td></tr>
<tr class="memitem:a52d64edda44be4ce464fd2b0ac4fccd0" id="r_a52d64edda44be4ce464fd2b0ac4fccd0"><td class="memItemLeft" align="right" valign="top">typedef struct gemma_llama_context&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#a52d64edda44be4ce464fd2b0ac4fccd0">gemma_llama_t</a></td></tr>
<tr class="memitem:a9918a8b838f2f089f5fa216db5f6fcbc" id="r_a9918a8b838f2f089f5fa216db5f6fcbc"><td class="memItemLeft" align="right" valign="top">typedef int(*&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#a9918a8b838f2f089f5fa216db5f6fcbc">gemma_token_callback</a>) (const char *token_text, void *user_data)</td></tr>
</table><table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 id="header-func-members" class="groupheader"><a id="func-members" name="func-members"></a>
Functions</h2></td></tr>
<tr class="memitem:aaf1f19f3f121e97040c5fbc9e6d055c6" id="r_aaf1f19f3f121e97040c5fbc9e6d055c6"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#aaf1f19f3f121e97040c5fbc9e6d055c6">gemma_default_runtime</a> (<a class="el" href="structgemma__runtime__config.html">gemma_runtime_config</a> *cfg)</td></tr>
<tr class="memitem:ad945475f5fbb0fc612be2cb3de0e3076" id="r_ad945475f5fbb0fc612be2cb3de0e3076"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#ad945475f5fbb0fc612be2cb3de0e3076">gemma_default_sampling</a> (<a class="el" href="structgemma__sampling__config.html">gemma_sampling_config</a> *cfg)</td></tr>
<tr class="memitem:a729e876bef94b34d08d69d800ff52b59" id="r_a729e876bef94b34d08d69d800ff52b59"><td class="memItemLeft" align="right" valign="top">int&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#a729e876bef94b34d08d69d800ff52b59">gemma_llama_init</a> (const char *model_path, const <a class="el" href="structgemma__runtime__config.html">gemma_runtime_config</a> *runtime, <a class="el" href="#a52d64edda44be4ce464fd2b0ac4fccd0">gemma_llama_t</a> **out_ctx, char *errbuf, size_t errbuf_size)</td></tr>
<tr class="memitem:aa4cc4ad3d0c07b4bd23d397039b9df21" id="r_aa4cc4ad3d0c07b4bd23d397039b9df21"><td class="memItemLeft" align="right" valign="top">int&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#aa4cc4ad3d0c07b4bd23d397039b9df21">gemma_llama_generate</a> (<a class="el" href="#a52d64edda44be4ce464fd2b0ac4fccd0">gemma_llama_t</a> *ctx, const char *prompt, const <a class="el" href="structgemma__sampling__config.html">gemma_sampling_config</a> *sampling, <a class="el" href="#a9918a8b838f2f089f5fa216db5f6fcbc">gemma_token_callback</a> on_token, void *user_data, char *errbuf, size_t errbuf_size)</td></tr>
<tr class="memitem:a9a12c78e4504a51c48d0241f9231773f" id="r_a9a12c78e4504a51c48d0241f9231773f"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#a9a12c78e4504a51c48d0241f9231773f">gemma_llama_free</a> (<a class="el" href="#a52d64edda44be4ce464fd2b0ac4fccd0">gemma_llama_t</a> *ctx)</td></tr>
</table>
<a name="doc-typedef-members" id="doc-typedef-members"></a><h2 id="header-doc-typedef-members" class="groupheader">Typedef Documentation</h2>
<a id="a52d64edda44be4ce464fd2b0ac4fccd0" name="a52d64edda44be4ce464fd2b0ac4fccd0"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a52d64edda44be4ce464fd2b0ac4fccd0">&#9670;&#160;</a></span>gemma_llama_t</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">typedef struct gemma_llama_context <a class="el" href="#a52d64edda44be4ce464fd2b0ac4fccd0">gemma_llama_t</a></td>
        </tr>
      </table>
</div><div class="memdoc">
<p>Opaque handle that owns llama.cpp model and context state. </p>

<p class="definition">Definition at line <a class="el" href="gemma__llama_8h_source.html#l00014">14</a> of file <a class="el" href="gemma__llama_8h_source.html">gemma_llama.h</a>.</p>

</div>
</div>
<a id="a9918a8b838f2f089f5fa216db5f6fcbc" name="a9918a8b838f2f089f5fa216db5f6fcbc"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a9918a8b838f2f089f5fa216db5f6fcbc">&#9670;&#160;</a></span>gemma_token_callback</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">typedef int(* gemma_token_callback) (const char *token_text, void *user_data)</td>
        </tr>
      </table>
</div><div class="memdoc">
<p>Streaming callback invoked for each token piece produced by the generator. Returning 0 aborts generation early, any non-zero value continues sampling. </p>

<p class="definition">Definition at line <a class="el" href="gemma__llama_8h_source.html#l00020">20</a> of file <a class="el" href="gemma__llama_8h_source.html">gemma_llama.h</a>.</p>

</div>
</div>
<a name="doc-func-members" id="doc-func-members"></a><h2 id="header-doc-func-members" class="groupheader">Function Documentation</h2>
<a id="aaf1f19f3f121e97040c5fbc9e6d055c6" name="aaf1f19f3f121e97040c5fbc9e6d055c6"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aaf1f19f3f121e97040c5fbc9e6d055c6">&#9670;&#160;</a></span>gemma_default_runtime()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">void gemma_default_runtime </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="structgemma__runtime__config.html">gemma_runtime_config</a> *</td>          <td class="paramname"><span class="paramname"><em>cfg</em></span></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<p>Writes recommended defaults into the runtime config struct. </p>

<p class="definition">Definition at line <a class="el" href="gemma__llama_8cpp_source.html#l00062">62</a> of file <a class="el" href="gemma__llama_8cpp_source.html">gemma_llama.cpp</a>.</p>
<div class="fragment"><div class="line"><span class="lineno">   62</span>                                                      {</div>
<div class="line"><span class="lineno">   63</span>    <span class="keywordflow">if</span> (!cfg) {</div>
<div class="line"><span class="lineno">   64</span>        <span class="keywordflow">return</span>;</div>
<div class="line"><span class="lineno">   65</span>    }</div>
<div class="line"><span class="lineno">   66</span>    cfg-&gt;<a class="code hl_variable" href="structgemma__runtime__config.html#a66e18c45bf39a21e5d7ce4a47cf3e4ba">n_ctx</a> = 4096;</div>
<div class="line"><span class="lineno">   67</span>    cfg-&gt;<a class="code hl_variable" href="structgemma__runtime__config.html#a44621855cb58b453984079384606993e">n_batch</a> = 512;</div>
<div class="line"><span class="lineno">   68</span>    cfg-&gt;<a class="code hl_variable" href="structgemma__runtime__config.html#ac8ef05e79800d7ed488399f6e56915c3">n_threads</a> = 0;</div>
<div class="line"><span class="lineno">   69</span>    cfg-&gt;<a class="code hl_variable" href="structgemma__runtime__config.html#ad780f2352af8763ba51a4d453ad8888d">n_gpu_layers</a> = 0;</div>
<div class="line"><span class="lineno">   70</span>    cfg-&gt;<a class="code hl_variable" href="structgemma__runtime__config.html#ae469f097c9df4ea415171356ed061d73">seed</a> = -1;</div>
<div class="line"><span class="lineno">   71</span>    cfg-&gt;<a class="code hl_variable" href="structgemma__runtime__config.html#af8ab449279a04b88c0b36001ad4ab600">main_gpu</a> = 0;</div>
<div class="line"><span class="lineno">   72</span>    cfg-&gt;<a class="code hl_variable" href="structgemma__runtime__config.html#af97928a8d4ca4c3354544f4635783485">split_mode</a> = 0;</div>
<div class="line"><span class="lineno">   73</span>    cfg-&gt;<a class="code hl_variable" href="structgemma__runtime__config.html#a7c1c013524220fd9e1efe779191bf3d6">use_mmap</a> = 1;</div>
<div class="line"><span class="lineno">   74</span>    cfg-&gt;<a class="code hl_variable" href="structgemma__runtime__config.html#a98e546bacc64cfa58eab2f49975008d0">use_mlock</a> = 0;</div>
<div class="line"><span class="lineno">   75</span>    cfg-&gt;<a class="code hl_variable" href="structgemma__runtime__config.html#ac3b23f6413b7f41772f3e537cbc6feb4">numa</a> = 0;</div>
<div class="line"><span class="lineno">   76</span>}</div>
<div class="ttc" id="astructgemma__runtime__config_html_a44621855cb58b453984079384606993e"><div class="ttname"><a href="structgemma__runtime__config.html#a44621855cb58b453984079384606993e">gemma_runtime_config::n_batch</a></div><div class="ttdeci">int32_t n_batch</div><div class="ttdef"><b>Definition</b> <a href="gemma__llama_8h_source.html#l00028">gemma_llama.h:28</a></div></div>
<div class="ttc" id="astructgemma__runtime__config_html_a66e18c45bf39a21e5d7ce4a47cf3e4ba"><div class="ttname"><a href="structgemma__runtime__config.html#a66e18c45bf39a21e5d7ce4a47cf3e4ba">gemma_runtime_config::n_ctx</a></div><div class="ttdeci">int32_t n_ctx</div><div class="ttdef"><b>Definition</b> <a href="gemma__llama_8h_source.html#l00027">gemma_llama.h:27</a></div></div>
<div class="ttc" id="astructgemma__runtime__config_html_a7c1c013524220fd9e1efe779191bf3d6"><div class="ttname"><a href="structgemma__runtime__config.html#a7c1c013524220fd9e1efe779191bf3d6">gemma_runtime_config::use_mmap</a></div><div class="ttdeci">int32_t use_mmap</div><div class="ttdef"><b>Definition</b> <a href="gemma__llama_8h_source.html#l00034">gemma_llama.h:34</a></div></div>
<div class="ttc" id="astructgemma__runtime__config_html_a98e546bacc64cfa58eab2f49975008d0"><div class="ttname"><a href="structgemma__runtime__config.html#a98e546bacc64cfa58eab2f49975008d0">gemma_runtime_config::use_mlock</a></div><div class="ttdeci">int32_t use_mlock</div><div class="ttdef"><b>Definition</b> <a href="gemma__llama_8h_source.html#l00035">gemma_llama.h:35</a></div></div>
<div class="ttc" id="astructgemma__runtime__config_html_ac3b23f6413b7f41772f3e537cbc6feb4"><div class="ttname"><a href="structgemma__runtime__config.html#ac3b23f6413b7f41772f3e537cbc6feb4">gemma_runtime_config::numa</a></div><div class="ttdeci">int32_t numa</div><div class="ttdef"><b>Definition</b> <a href="gemma__llama_8h_source.html#l00036">gemma_llama.h:36</a></div></div>
<div class="ttc" id="astructgemma__runtime__config_html_ac8ef05e79800d7ed488399f6e56915c3"><div class="ttname"><a href="structgemma__runtime__config.html#ac8ef05e79800d7ed488399f6e56915c3">gemma_runtime_config::n_threads</a></div><div class="ttdeci">int32_t n_threads</div><div class="ttdef"><b>Definition</b> <a href="gemma__llama_8h_source.html#l00029">gemma_llama.h:29</a></div></div>
<div class="ttc" id="astructgemma__runtime__config_html_ad780f2352af8763ba51a4d453ad8888d"><div class="ttname"><a href="structgemma__runtime__config.html#ad780f2352af8763ba51a4d453ad8888d">gemma_runtime_config::n_gpu_layers</a></div><div class="ttdeci">int32_t n_gpu_layers</div><div class="ttdef"><b>Definition</b> <a href="gemma__llama_8h_source.html#l00030">gemma_llama.h:30</a></div></div>
<div class="ttc" id="astructgemma__runtime__config_html_ae469f097c9df4ea415171356ed061d73"><div class="ttname"><a href="structgemma__runtime__config.html#ae469f097c9df4ea415171356ed061d73">gemma_runtime_config::seed</a></div><div class="ttdeci">int32_t seed</div><div class="ttdef"><b>Definition</b> <a href="gemma__llama_8h_source.html#l00031">gemma_llama.h:31</a></div></div>
<div class="ttc" id="astructgemma__runtime__config_html_af8ab449279a04b88c0b36001ad4ab600"><div class="ttname"><a href="structgemma__runtime__config.html#af8ab449279a04b88c0b36001ad4ab600">gemma_runtime_config::main_gpu</a></div><div class="ttdeci">int32_t main_gpu</div><div class="ttdef"><b>Definition</b> <a href="gemma__llama_8h_source.html#l00032">gemma_llama.h:32</a></div></div>
<div class="ttc" id="astructgemma__runtime__config_html_af97928a8d4ca4c3354544f4635783485"><div class="ttname"><a href="structgemma__runtime__config.html#af97928a8d4ca4c3354544f4635783485">gemma_runtime_config::split_mode</a></div><div class="ttdeci">int32_t split_mode</div><div class="ttdef"><b>Definition</b> <a href="gemma__llama_8h_source.html#l00033">gemma_llama.h:33</a></div></div>
</div><!-- fragment -->
<p class="reference">References <a class="el" href="gemma__llama_8h_source.html#l00032">gemma_runtime_config::main_gpu</a>, <a class="el" href="gemma__llama_8h_source.html#l00028">gemma_runtime_config::n_batch</a>, <a class="el" href="gemma__llama_8h_source.html#l00027">gemma_runtime_config::n_ctx</a>, <a class="el" href="gemma__llama_8h_source.html#l00030">gemma_runtime_config::n_gpu_layers</a>, <a class="el" href="gemma__llama_8h_source.html#l00029">gemma_runtime_config::n_threads</a>, <a class="el" href="gemma__llama_8h_source.html#l00036">gemma_runtime_config::numa</a>, <a class="el" href="gemma__llama_8h_source.html#l00031">gemma_runtime_config::seed</a>, <a class="el" href="gemma__llama_8h_source.html#l00033">gemma_runtime_config::split_mode</a>, <a class="el" href="gemma__llama_8h_source.html#l00035">gemma_runtime_config::use_mlock</a>, and <a class="el" href="gemma__llama_8h_source.html#l00034">gemma_runtime_config::use_mmap</a>.</p>

<p class="reference">Referenced by <a class="el" href="gemma__llama_8cpp_source.html#l00096">gemma_llama_init()</a>, and <a class="el" href="gemma__cli_8c_source.html#l00041">main()</a>.</p>
<div id="dynsection-2" onclick="return dynsection.toggleVisibility(this)" class="dynheader closed" style="cursor:pointer;"><span class="dynarrow"><span class="arrowhead closed"></span></span>Here is the caller graph for this function:</div>
<div id="dynsection-2-summary" class="dynsummary" style="display:block;">
</div>
<div id="dynsection-2-content" class="dyncontent" style="display:none;">
<div class="center"><iframe scrolling="no" loading="lazy" frameborder="0" src="gemma__llama_8h_aaf1f19f3f121e97040c5fbc9e6d055c6_icgraph.svg" width="443" height="62"><p><b>This browser is not able to show SVG: try Firefox, Chrome, Safari, or Opera instead.</b></p></iframe></div>
</div>

</div>
</div>
<a id="ad945475f5fbb0fc612be2cb3de0e3076" name="ad945475f5fbb0fc612be2cb3de0e3076"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ad945475f5fbb0fc612be2cb3de0e3076">&#9670;&#160;</a></span>gemma_default_sampling()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">void gemma_default_sampling </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="structgemma__sampling__config.html">gemma_sampling_config</a> *</td>          <td class="paramname"><span class="paramname"><em>cfg</em></span></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<p>Writes recommended defaults into the sampling config struct. </p>

<p class="definition">Definition at line <a class="el" href="gemma__llama_8cpp_source.html#l00078">78</a> of file <a class="el" href="gemma__llama_8cpp_source.html">gemma_llama.cpp</a>.</p>
<div class="fragment"><div class="line"><span class="lineno">   78</span>                                                        {</div>
<div class="line"><span class="lineno">   79</span>    <span class="keywordflow">if</span> (!cfg) {</div>
<div class="line"><span class="lineno">   80</span>        <span class="keywordflow">return</span>;</div>
<div class="line"><span class="lineno">   81</span>    }</div>
<div class="line"><span class="lineno">   82</span>    cfg-&gt;<a class="code hl_variable" href="structgemma__sampling__config.html#aad581ae866b02f25535ffc54efbc5038">max_new_tokens</a> = 256;</div>
<div class="line"><span class="lineno">   83</span>    cfg-&gt;<a class="code hl_variable" href="structgemma__sampling__config.html#a7ca1b736dcf9b3776bef1bc3fc4f05a3">temperature</a> = 0.7f;</div>
<div class="line"><span class="lineno">   84</span>    cfg-&gt;<a class="code hl_variable" href="structgemma__sampling__config.html#a2a7ebbdc81298f707ed9b5aa3c642603">top_p</a> = 0.95f;</div>
<div class="line"><span class="lineno">   85</span>    cfg-&gt;<a class="code hl_variable" href="structgemma__sampling__config.html#a11aa604f5b0a8a7295866f0938edc0bf">top_k</a> = 40;</div>
<div class="line"><span class="lineno">   86</span>    cfg-&gt;<a class="code hl_variable" href="structgemma__sampling__config.html#aaceeb5b73e55a2dbe2c9ba7890ab6086">repetition_penalty</a> = 1.1f;</div>
<div class="line"><span class="lineno">   87</span>    cfg-&gt;<a class="code hl_variable" href="structgemma__sampling__config.html#a301ac37dabd8386a881c87bfd75b0bc9">repetition_last_n</a> = 128;</div>
<div class="line"><span class="lineno">   88</span>    cfg-&gt;<a class="code hl_variable" href="structgemma__sampling__config.html#a5e2c6fbf1a3fe7de72d34f5dd518b9bc">frequency_penalty</a> = 0.0f;</div>
<div class="line"><span class="lineno">   89</span>    cfg-&gt;<a class="code hl_variable" href="structgemma__sampling__config.html#aea6cf49b95d6f3d3eaf00c89fbbfd715">presence_penalty</a> = 0.0f;</div>
<div class="line"><span class="lineno">   90</span>    cfg-&gt;<a class="code hl_variable" href="structgemma__sampling__config.html#aa4d8eb66623b285d6fa1ef0953480059">min_p</a> = 0.0f;</div>
<div class="line"><span class="lineno">   91</span>    cfg-&gt;<a class="code hl_variable" href="structgemma__sampling__config.html#a7e0b57c65ece909e3545d4a6d21ba82b">typical_p</a> = 0.0f;</div>
<div class="line"><span class="lineno">   92</span>    cfg-&gt;<a class="code hl_variable" href="structgemma__sampling__config.html#a5ab8039031aa1ccde9eefd8708ca5e30">logit_biases</a> = NULL;</div>
<div class="line"><span class="lineno">   93</span>    cfg-&gt;<a class="code hl_variable" href="structgemma__sampling__config.html#aafa252390ecf52cbc6474140a42c7496">num_logit_biases</a> = 0;</div>
<div class="line"><span class="lineno">   94</span>}</div>
<div class="ttc" id="astructgemma__sampling__config_html_a11aa604f5b0a8a7295866f0938edc0bf"><div class="ttname"><a href="structgemma__sampling__config.html#a11aa604f5b0a8a7295866f0938edc0bf">gemma_sampling_config::top_k</a></div><div class="ttdeci">int32_t top_k</div><div class="ttdef"><b>Definition</b> <a href="gemma__llama_8h_source.html#l00052">gemma_llama.h:52</a></div></div>
<div class="ttc" id="astructgemma__sampling__config_html_a2a7ebbdc81298f707ed9b5aa3c642603"><div class="ttname"><a href="structgemma__sampling__config.html#a2a7ebbdc81298f707ed9b5aa3c642603">gemma_sampling_config::top_p</a></div><div class="ttdeci">float top_p</div><div class="ttdef"><b>Definition</b> <a href="gemma__llama_8h_source.html#l00051">gemma_llama.h:51</a></div></div>
<div class="ttc" id="astructgemma__sampling__config_html_a301ac37dabd8386a881c87bfd75b0bc9"><div class="ttname"><a href="structgemma__sampling__config.html#a301ac37dabd8386a881c87bfd75b0bc9">gemma_sampling_config::repetition_last_n</a></div><div class="ttdeci">int32_t repetition_last_n</div><div class="ttdef"><b>Definition</b> <a href="gemma__llama_8h_source.html#l00054">gemma_llama.h:54</a></div></div>
<div class="ttc" id="astructgemma__sampling__config_html_a5ab8039031aa1ccde9eefd8708ca5e30"><div class="ttname"><a href="structgemma__sampling__config.html#a5ab8039031aa1ccde9eefd8708ca5e30">gemma_sampling_config::logit_biases</a></div><div class="ttdeci">const gemma_logit_bias_entry * logit_biases</div><div class="ttdef"><b>Definition</b> <a href="gemma__llama_8h_source.html#l00059">gemma_llama.h:59</a></div></div>
<div class="ttc" id="astructgemma__sampling__config_html_a5e2c6fbf1a3fe7de72d34f5dd518b9bc"><div class="ttname"><a href="structgemma__sampling__config.html#a5e2c6fbf1a3fe7de72d34f5dd518b9bc">gemma_sampling_config::frequency_penalty</a></div><div class="ttdeci">float frequency_penalty</div><div class="ttdef"><b>Definition</b> <a href="gemma__llama_8h_source.html#l00055">gemma_llama.h:55</a></div></div>
<div class="ttc" id="astructgemma__sampling__config_html_a7ca1b736dcf9b3776bef1bc3fc4f05a3"><div class="ttname"><a href="structgemma__sampling__config.html#a7ca1b736dcf9b3776bef1bc3fc4f05a3">gemma_sampling_config::temperature</a></div><div class="ttdeci">float temperature</div><div class="ttdef"><b>Definition</b> <a href="gemma__llama_8h_source.html#l00050">gemma_llama.h:50</a></div></div>
<div class="ttc" id="astructgemma__sampling__config_html_a7e0b57c65ece909e3545d4a6d21ba82b"><div class="ttname"><a href="structgemma__sampling__config.html#a7e0b57c65ece909e3545d4a6d21ba82b">gemma_sampling_config::typical_p</a></div><div class="ttdeci">float typical_p</div><div class="ttdef"><b>Definition</b> <a href="gemma__llama_8h_source.html#l00058">gemma_llama.h:58</a></div></div>
<div class="ttc" id="astructgemma__sampling__config_html_aa4d8eb66623b285d6fa1ef0953480059"><div class="ttname"><a href="structgemma__sampling__config.html#aa4d8eb66623b285d6fa1ef0953480059">gemma_sampling_config::min_p</a></div><div class="ttdeci">float min_p</div><div class="ttdef"><b>Definition</b> <a href="gemma__llama_8h_source.html#l00057">gemma_llama.h:57</a></div></div>
<div class="ttc" id="astructgemma__sampling__config_html_aaceeb5b73e55a2dbe2c9ba7890ab6086"><div class="ttname"><a href="structgemma__sampling__config.html#aaceeb5b73e55a2dbe2c9ba7890ab6086">gemma_sampling_config::repetition_penalty</a></div><div class="ttdeci">float repetition_penalty</div><div class="ttdef"><b>Definition</b> <a href="gemma__llama_8h_source.html#l00053">gemma_llama.h:53</a></div></div>
<div class="ttc" id="astructgemma__sampling__config_html_aad581ae866b02f25535ffc54efbc5038"><div class="ttname"><a href="structgemma__sampling__config.html#aad581ae866b02f25535ffc54efbc5038">gemma_sampling_config::max_new_tokens</a></div><div class="ttdeci">int32_t max_new_tokens</div><div class="ttdef"><b>Definition</b> <a href="gemma__llama_8h_source.html#l00049">gemma_llama.h:49</a></div></div>
<div class="ttc" id="astructgemma__sampling__config_html_aafa252390ecf52cbc6474140a42c7496"><div class="ttname"><a href="structgemma__sampling__config.html#aafa252390ecf52cbc6474140a42c7496">gemma_sampling_config::num_logit_biases</a></div><div class="ttdeci">size_t num_logit_biases</div><div class="ttdef"><b>Definition</b> <a href="gemma__llama_8h_source.html#l00060">gemma_llama.h:60</a></div></div>
<div class="ttc" id="astructgemma__sampling__config_html_aea6cf49b95d6f3d3eaf00c89fbbfd715"><div class="ttname"><a href="structgemma__sampling__config.html#aea6cf49b95d6f3d3eaf00c89fbbfd715">gemma_sampling_config::presence_penalty</a></div><div class="ttdeci">float presence_penalty</div><div class="ttdef"><b>Definition</b> <a href="gemma__llama_8h_source.html#l00056">gemma_llama.h:56</a></div></div>
</div><!-- fragment -->
<p class="reference">References <a class="el" href="gemma__llama_8h_source.html#l00055">gemma_sampling_config::frequency_penalty</a>, <a class="el" href="gemma__llama_8h_source.html#l00059">gemma_sampling_config::logit_biases</a>, <a class="el" href="gemma__llama_8h_source.html#l00049">gemma_sampling_config::max_new_tokens</a>, <a class="el" href="gemma__llama_8h_source.html#l00057">gemma_sampling_config::min_p</a>, <a class="el" href="gemma__llama_8h_source.html#l00060">gemma_sampling_config::num_logit_biases</a>, <a class="el" href="gemma__llama_8h_source.html#l00056">gemma_sampling_config::presence_penalty</a>, <a class="el" href="gemma__llama_8h_source.html#l00054">gemma_sampling_config::repetition_last_n</a>, <a class="el" href="gemma__llama_8h_source.html#l00053">gemma_sampling_config::repetition_penalty</a>, <a class="el" href="gemma__llama_8h_source.html#l00050">gemma_sampling_config::temperature</a>, <a class="el" href="gemma__llama_8h_source.html#l00052">gemma_sampling_config::top_k</a>, <a class="el" href="gemma__llama_8h_source.html#l00051">gemma_sampling_config::top_p</a>, and <a class="el" href="gemma__llama_8h_source.html#l00058">gemma_sampling_config::typical_p</a>.</p>

<p class="reference">Referenced by <a class="el" href="gemma__llama_8cpp_source.html#l00173">gemma_llama_generate()</a>, and <a class="el" href="gemma__cli_8c_source.html#l00041">main()</a>.</p>
<div id="dynsection-3" onclick="return dynsection.toggleVisibility(this)" class="dynheader closed" style="cursor:pointer;"><span class="dynarrow"><span class="arrowhead closed"></span></span>Here is the caller graph for this function:</div>
<div id="dynsection-3-summary" class="dynsummary" style="display:block;">
</div>
<div id="dynsection-3-content" class="dyncontent" style="display:none;">
<div class="center"><iframe scrolling="no" loading="lazy" frameborder="0" src="gemma__llama_8h_ad945475f5fbb0fc612be2cb3de0e3076_icgraph.svg" width="486" height="62"><p><b>This browser is not able to show SVG: try Firefox, Chrome, Safari, or Opera instead.</b></p></iframe></div>
</div>

</div>
</div>
<a id="a9a12c78e4504a51c48d0241f9231773f" name="a9a12c78e4504a51c48d0241f9231773f"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a9a12c78e4504a51c48d0241f9231773f">&#9670;&#160;</a></span>gemma_llama_free()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">void gemma_llama_free </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="#a52d64edda44be4ce464fd2b0ac4fccd0">gemma_llama_t</a> *</td>          <td class="paramname"><span class="paramname"><em>ctx</em></span></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<p>Releases llama.cpp resources. Safe to call on NULL handles. </p>

<p class="definition">Definition at line <a class="el" href="gemma__llama_8cpp_source.html#l00473">473</a> of file <a class="el" href="gemma__llama_8cpp_source.html">gemma_llama.cpp</a>.</p>
<div class="fragment"><div class="line"><span class="lineno">  473</span>                                          {</div>
<div class="line"><span class="lineno">  474</span>    <span class="keywordflow">if</span> (!ctx) {</div>
<div class="line"><span class="lineno">  475</span>        <span class="keywordflow">return</span>;</div>
<div class="line"><span class="lineno">  476</span>    }</div>
<div class="line"><span class="lineno">  477</span>    llama_free(ctx-&gt;ctx);</div>
<div class="line"><span class="lineno">  478</span>    llama_model_free(ctx-&gt;model);</div>
<div class="line"><span class="lineno">  479</span>    <span class="keyword">delete</span> ctx;</div>
<div class="line"><span class="lineno">  480</span>    <span class="keywordflow">if</span> (g_active_contexts.fetch_sub(1, std::memory_order_relaxed) == 1) {</div>
<div class="line"><span class="lineno">  481</span>        llama_backend_free();</div>
<div class="line"><span class="lineno">  482</span>    }</div>
<div class="line"><span class="lineno">  483</span>}</div>
</div><!-- fragment -->
<p class="reference">Referenced by <a class="el" href="gemma__cli_8c_source.html#l00041">main()</a>.</p>
<div id="dynsection-4" onclick="return dynsection.toggleVisibility(this)" class="dynheader closed" style="cursor:pointer;"><span class="dynarrow"><span class="arrowhead closed"></span></span>Here is the caller graph for this function:</div>
<div id="dynsection-4-summary" class="dynsummary" style="display:block;">
</div>
<div id="dynsection-4-content" class="dyncontent" style="display:none;">
<div class="center"><iframe scrolling="no" loading="lazy" frameborder="0" src="gemma__llama_8h_a9a12c78e4504a51c48d0241f9231773f_icgraph.svg" width="240" height="36"><p><b>This browser is not able to show SVG: try Firefox, Chrome, Safari, or Opera instead.</b></p></iframe></div>
</div>

</div>
</div>
<a id="aa4cc4ad3d0c07b4bd23d397039b9df21" name="aa4cc4ad3d0c07b4bd23d397039b9df21"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aa4cc4ad3d0c07b4bd23d397039b9df21">&#9670;&#160;</a></span>gemma_llama_generate()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">int gemma_llama_generate </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="#a52d64edda44be4ce464fd2b0ac4fccd0">gemma_llama_t</a> *</td>          <td class="paramname"><span class="paramname"><em>ctx</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const char *</td>          <td class="paramname"><span class="paramname"><em>prompt</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="structgemma__sampling__config.html">gemma_sampling_config</a> *</td>          <td class="paramname"><span class="paramname"><em>sampling</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="#a9918a8b838f2f089f5fa216db5f6fcbc">gemma_token_callback</a></td>          <td class="paramname"><span class="paramname"><em>on_token</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">void *</td>          <td class="paramname"><span class="paramname"><em>user_data</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">char *</td>          <td class="paramname"><span class="paramname"><em>errbuf</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">size_t</td>          <td class="paramname"><span class="paramname"><em>errbuf_size</em></span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">
<p>Generates text streamed through the provided callback.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">ctx</td><td>Context returned by gemma_llama_init. </td></tr>
    <tr><td class="paramname">prompt</td><td>UTF-8 prompt string. </td></tr>
    <tr><td class="paramname">sampling</td><td>Optional sampling overrides; NULL applies defaults. </td></tr>
    <tr><td class="paramname">on_token</td><td>Optional streaming callback (may be NULL for buffered use). </td></tr>
    <tr><td class="paramname">user_data</td><td>User pointer forwarded to callback. </td></tr>
    <tr><td class="paramname">errbuf</td><td>Optional buffer for errors. </td></tr>
    <tr><td class="paramname">errbuf_size</td><td>Size of errbuf. </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>0 when full generation succeeds, &gt;0 if aborted by callback, &lt;0 on error. </dd></dl>

<p class="definition">Definition at line <a class="el" href="gemma__llama_8cpp_source.html#l00173">173</a> of file <a class="el" href="gemma__llama_8cpp_source.html">gemma_llama.cpp</a>.</p>
<div class="fragment"><div class="line"><span class="lineno">  179</span>                                             {</div>
<div class="line"><span class="lineno">  180</span>    <span class="keywordflow">if</span> (!ctx || !prompt) {</div>
<div class="line"><span class="lineno">  181</span>        copy_error(<span class="stringliteral">&quot;ctx or prompt is null&quot;</span>, errbuf, errbuf_size);</div>
<div class="line"><span class="lineno">  182</span>        <span class="keywordflow">return</span> -1;</div>
<div class="line"><span class="lineno">  183</span>    }</div>
<div class="line"><span class="lineno">  184</span> </div>
<div class="line"><span class="lineno">  185</span>    <a class="code hl_struct" href="structgemma__sampling__config.html">gemma_sampling_config</a> smp;</div>
<div class="line"><span class="lineno">  186</span>    <a class="code hl_function" href="gemma__llama_8cpp.html#ad945475f5fbb0fc612be2cb3de0e3076">gemma_default_sampling</a>(&amp;smp);</div>
<div class="line"><span class="lineno">  187</span>    <span class="keywordflow">if</span> (sampling) {</div>
<div class="line"><span class="lineno">  188</span>        smp = *sampling;</div>
<div class="line"><span class="lineno">  189</span>    }</div>
<div class="line"><span class="lineno">  190</span> </div>
<div class="line"><span class="lineno">  191</span>    <span class="keyword">const</span> int32_t max_new = smp.<a class="code hl_variable" href="structgemma__sampling__config.html#aad581ae866b02f25535ffc54efbc5038">max_new_tokens</a> &gt; 0 ? smp.<a class="code hl_variable" href="structgemma__sampling__config.html#aad581ae866b02f25535ffc54efbc5038">max_new_tokens</a> : 256;</div>
<div class="line"><span class="lineno">  192</span>    <span class="keyword">const</span> int32_t repeat_last_n = smp.<a class="code hl_variable" href="structgemma__sampling__config.html#a301ac37dabd8386a881c87bfd75b0bc9">repetition_last_n</a> &gt; 0 ? smp.<a class="code hl_variable" href="structgemma__sampling__config.html#a301ac37dabd8386a881c87bfd75b0bc9">repetition_last_n</a> : 128;</div>
<div class="line"><span class="lineno">  193</span>    <span class="keyword">const</span> <span class="keywordtype">float</span> repeat_penalty = smp.<a class="code hl_variable" href="structgemma__sampling__config.html#aaceeb5b73e55a2dbe2c9ba7890ab6086">repetition_penalty</a> &gt; 0.0f ? smp.<a class="code hl_variable" href="structgemma__sampling__config.html#aaceeb5b73e55a2dbe2c9ba7890ab6086">repetition_penalty</a> : 1.0f;</div>
<div class="line"><span class="lineno">  194</span> </div>
<div class="line"><span class="lineno">  195</span>    llama_memory_clear(llama_get_memory(ctx-&gt;ctx), <span class="keyword">true</span>);</div>
<div class="line"><span class="lineno">  196</span> </div>
<div class="line"><span class="lineno">  197</span>    <span class="keyword">const</span> llama_vocab *vocab = llama_model_get_vocab(ctx-&gt;model);</div>
<div class="line"><span class="lineno">  198</span>    <span class="keywordflow">if</span> (!vocab) {</div>
<div class="line"><span class="lineno">  199</span>        copy_error(<span class="stringliteral">&quot;failed to access vocabulary&quot;</span>, errbuf, errbuf_size);</div>
<div class="line"><span class="lineno">  200</span>        <span class="keywordflow">return</span> -1;</div>
<div class="line"><span class="lineno">  201</span>    }</div>
<div class="line"><span class="lineno">  202</span> </div>
<div class="line"><span class="lineno">  203</span>    <span class="keyword">const</span> <span class="keywordtype">size_t</span> prompt_len_bytes = std::strlen(prompt);</div>
<div class="line"><span class="lineno">  204</span>    int32_t prompt_len = llama_tokenize(vocab, prompt, <span class="keyword">static_cast&lt;</span>int32_t<span class="keyword">&gt;</span>(prompt_len_bytes), <span class="keyword">nullptr</span>, 0, <span class="keyword">true</span>, <span class="keyword">true</span>);</div>
<div class="line"><span class="lineno">  205</span>    <span class="keywordflow">if</span> (prompt_len &lt; 0) {</div>
<div class="line"><span class="lineno">  206</span>        prompt_len = -prompt_len;</div>
<div class="line"><span class="lineno">  207</span>    }</div>
<div class="line"><span class="lineno">  208</span>    <span class="keywordflow">if</span> (prompt_len &lt;= 0) {</div>
<div class="line"><span class="lineno">  209</span>        copy_error(<span class="stringliteral">&quot;failed to tokenize prompt&quot;</span>, errbuf, errbuf_size);</div>
<div class="line"><span class="lineno">  210</span>        <span class="keywordflow">return</span> -1;</div>
<div class="line"><span class="lineno">  211</span>    }</div>
<div class="line"><span class="lineno">  212</span> </div>
<div class="line"><span class="lineno">  213</span>    <span class="keyword">const</span> uint32_t ctx_limit = llama_n_ctx(ctx-&gt;ctx);</div>
<div class="line"><span class="lineno">  214</span>    <span class="keywordflow">if</span> (<span class="keyword">static_cast&lt;</span>uint32_t<span class="keyword">&gt;</span>(prompt_len) &gt;= ctx_limit) {</div>
<div class="line"><span class="lineno">  215</span>        copy_error(<span class="stringliteral">&quot;prompt is longer than context window&quot;</span>, errbuf, errbuf_size);</div>
<div class="line"><span class="lineno">  216</span>        <span class="keywordflow">return</span> -1;</div>
<div class="line"><span class="lineno">  217</span>    }</div>
<div class="line"><span class="lineno">  218</span> </div>
<div class="line"><span class="lineno">  219</span>    std::vector&lt;llama_token&gt; prompt_tokens(<span class="keyword">static_cast&lt;</span><span class="keywordtype">size_t</span><span class="keyword">&gt;</span>(prompt_len));</div>
<div class="line"><span class="lineno">  220</span>    <span class="keywordflow">if</span> (llama_tokenize(vocab,</div>
<div class="line"><span class="lineno">  221</span>                       prompt,</div>
<div class="line"><span class="lineno">  222</span>                       <span class="keyword">static_cast&lt;</span>int32_t<span class="keyword">&gt;</span>(prompt_len_bytes),</div>
<div class="line"><span class="lineno">  223</span>                       prompt_tokens.data(),</div>
<div class="line"><span class="lineno">  224</span>                       prompt_len,</div>
<div class="line"><span class="lineno">  225</span>                       <span class="keyword">true</span>,</div>
<div class="line"><span class="lineno">  226</span>                       <span class="keyword">true</span>) &lt; 0) {</div>
<div class="line"><span class="lineno">  227</span>        copy_error(<span class="stringliteral">&quot;failed to tokenize prompt&quot;</span>, errbuf, errbuf_size);</div>
<div class="line"><span class="lineno">  228</span>        <span class="keywordflow">return</span> -1;</div>
<div class="line"><span class="lineno">  229</span>    }</div>
<div class="line"><span class="lineno">  230</span> </div>
<div class="line"><span class="lineno">  231</span>    <span class="keyword">auto</span> chain_params = llama_sampler_chain_default_params();</div>
<div class="line"><span class="lineno">  232</span>    chain_params.no_perf = <span class="keyword">false</span>;</div>
<div class="line"><span class="lineno">  233</span>    llama_sampler *sampler = llama_sampler_chain_init(chain_params);</div>
<div class="line"><span class="lineno">  234</span>    <span class="keywordflow">if</span> (!sampler) {</div>
<div class="line"><span class="lineno">  235</span>        copy_error(<span class="stringliteral">&quot;failed to initialize sampler&quot;</span>, errbuf, errbuf_size);</div>
<div class="line"><span class="lineno">  236</span>        <span class="keywordflow">return</span> -1;</div>
<div class="line"><span class="lineno">  237</span>    }</div>
<div class="line"><span class="lineno">  238</span> </div>
<div class="line"><span class="lineno">  239</span>    <span class="keywordflow">if</span> (repeat_last_n &gt; 0 &amp;&amp; (repeat_penalty &gt; 1.0f || smp.<a class="code hl_variable" href="structgemma__sampling__config.html#a5e2c6fbf1a3fe7de72d34f5dd518b9bc">frequency_penalty</a> &gt; 0.0f || smp.<a class="code hl_variable" href="structgemma__sampling__config.html#aea6cf49b95d6f3d3eaf00c89fbbfd715">presence_penalty</a> &gt; 0.0f)) {</div>
<div class="line"><span class="lineno">  240</span>        <span class="keyword">const</span> <span class="keywordtype">float</span> use_repeat_penalty = repeat_penalty &gt; 0.0f ? repeat_penalty : 1.0f;</div>
<div class="line"><span class="lineno">  241</span>        llama_sampler *penalties = llama_sampler_init_penalties(repeat_last_n,</div>
<div class="line"><span class="lineno">  242</span>                                                                use_repeat_penalty,</div>
<div class="line"><span class="lineno">  243</span>                                                                smp.<a class="code hl_variable" href="structgemma__sampling__config.html#a5e2c6fbf1a3fe7de72d34f5dd518b9bc">frequency_penalty</a>,</div>
<div class="line"><span class="lineno">  244</span>                                                                smp.<a class="code hl_variable" href="structgemma__sampling__config.html#aea6cf49b95d6f3d3eaf00c89fbbfd715">presence_penalty</a>);</div>
<div class="line"><span class="lineno">  245</span>        <span class="keywordflow">if</span> (!penalties) {</div>
<div class="line"><span class="lineno">  246</span>            llama_sampler_free(sampler);</div>
<div class="line"><span class="lineno">  247</span>            copy_error(<span class="stringliteral">&quot;failed to initialise repetition penalty sampler&quot;</span>, errbuf, errbuf_size);</div>
<div class="line"><span class="lineno">  248</span>            <span class="keywordflow">return</span> -1;</div>
<div class="line"><span class="lineno">  249</span>        }</div>
<div class="line"><span class="lineno">  250</span>        llama_sampler_chain_add(sampler, penalties);</div>
<div class="line"><span class="lineno">  251</span>    }</div>
<div class="line"><span class="lineno">  252</span>    <span class="keywordflow">if</span> (smp.<a class="code hl_variable" href="structgemma__sampling__config.html#a11aa604f5b0a8a7295866f0938edc0bf">top_k</a> &gt; 0) {</div>
<div class="line"><span class="lineno">  253</span>        llama_sampler *top_k = llama_sampler_init_top_k(smp.<a class="code hl_variable" href="structgemma__sampling__config.html#a11aa604f5b0a8a7295866f0938edc0bf">top_k</a>);</div>
<div class="line"><span class="lineno">  254</span>        <span class="keywordflow">if</span> (!top_k) {</div>
<div class="line"><span class="lineno">  255</span>            llama_sampler_free(sampler);</div>
<div class="line"><span class="lineno">  256</span>            copy_error(<span class="stringliteral">&quot;failed to initialise top-k sampler&quot;</span>, errbuf, errbuf_size);</div>
<div class="line"><span class="lineno">  257</span>            <span class="keywordflow">return</span> -1;</div>
<div class="line"><span class="lineno">  258</span>        }</div>
<div class="line"><span class="lineno">  259</span>        llama_sampler_chain_add(sampler, top_k);</div>
<div class="line"><span class="lineno">  260</span>    }</div>
<div class="line"><span class="lineno">  261</span>    <span class="keywordflow">if</span> (smp.<a class="code hl_variable" href="structgemma__sampling__config.html#a2a7ebbdc81298f707ed9b5aa3c642603">top_p</a> &gt; 0.0f &amp;&amp; smp.<a class="code hl_variable" href="structgemma__sampling__config.html#a2a7ebbdc81298f707ed9b5aa3c642603">top_p</a> &lt; 1.0f) {</div>
<div class="line"><span class="lineno">  262</span>        llama_sampler *top_p = llama_sampler_init_top_p(smp.<a class="code hl_variable" href="structgemma__sampling__config.html#a2a7ebbdc81298f707ed9b5aa3c642603">top_p</a>, 1);</div>
<div class="line"><span class="lineno">  263</span>        <span class="keywordflow">if</span> (!top_p) {</div>
<div class="line"><span class="lineno">  264</span>            llama_sampler_free(sampler);</div>
<div class="line"><span class="lineno">  265</span>            copy_error(<span class="stringliteral">&quot;failed to initialise top-p sampler&quot;</span>, errbuf, errbuf_size);</div>
<div class="line"><span class="lineno">  266</span>            <span class="keywordflow">return</span> -1;</div>
<div class="line"><span class="lineno">  267</span>        }</div>
<div class="line"><span class="lineno">  268</span>        llama_sampler_chain_add(sampler, top_p);</div>
<div class="line"><span class="lineno">  269</span>    }</div>
<div class="line"><span class="lineno">  270</span>    <span class="keywordflow">if</span> (smp.<a class="code hl_variable" href="structgemma__sampling__config.html#aa4d8eb66623b285d6fa1ef0953480059">min_p</a> &gt; 0.0f &amp;&amp; smp.<a class="code hl_variable" href="structgemma__sampling__config.html#aa4d8eb66623b285d6fa1ef0953480059">min_p</a> &lt; 1.0f) {</div>
<div class="line"><span class="lineno">  271</span>        llama_sampler *min_p = llama_sampler_init_min_p(smp.<a class="code hl_variable" href="structgemma__sampling__config.html#aa4d8eb66623b285d6fa1ef0953480059">min_p</a>, 1);</div>
<div class="line"><span class="lineno">  272</span>        <span class="keywordflow">if</span> (!min_p) {</div>
<div class="line"><span class="lineno">  273</span>            llama_sampler_free(sampler);</div>
<div class="line"><span class="lineno">  274</span>            copy_error(<span class="stringliteral">&quot;failed to initialise min-p sampler&quot;</span>, errbuf, errbuf_size);</div>
<div class="line"><span class="lineno">  275</span>            <span class="keywordflow">return</span> -1;</div>
<div class="line"><span class="lineno">  276</span>        }</div>
<div class="line"><span class="lineno">  277</span>        llama_sampler_chain_add(sampler, min_p);</div>
<div class="line"><span class="lineno">  278</span>    }</div>
<div class="line"><span class="lineno">  279</span>    <span class="keywordflow">if</span> (smp.<a class="code hl_variable" href="structgemma__sampling__config.html#a7e0b57c65ece909e3545d4a6d21ba82b">typical_p</a> &gt; 0.0f &amp;&amp; smp.<a class="code hl_variable" href="structgemma__sampling__config.html#a7e0b57c65ece909e3545d4a6d21ba82b">typical_p</a> &lt; 1.0f) {</div>
<div class="line"><span class="lineno">  280</span>        llama_sampler *typical = llama_sampler_init_typical(smp.<a class="code hl_variable" href="structgemma__sampling__config.html#a7e0b57c65ece909e3545d4a6d21ba82b">typical_p</a>, 1);</div>
<div class="line"><span class="lineno">  281</span>        <span class="keywordflow">if</span> (!typical) {</div>
<div class="line"><span class="lineno">  282</span>            llama_sampler_free(sampler);</div>
<div class="line"><span class="lineno">  283</span>            copy_error(<span class="stringliteral">&quot;failed to initialise typical sampler&quot;</span>, errbuf, errbuf_size);</div>
<div class="line"><span class="lineno">  284</span>            <span class="keywordflow">return</span> -1;</div>
<div class="line"><span class="lineno">  285</span>        }</div>
<div class="line"><span class="lineno">  286</span>        llama_sampler_chain_add(sampler, typical);</div>
<div class="line"><span class="lineno">  287</span>    }</div>
<div class="line"><span class="lineno">  288</span> </div>
<div class="line"><span class="lineno">  289</span>    llama_sampler *logit_bias_sampler = <span class="keyword">nullptr</span>;</div>
<div class="line"><span class="lineno">  290</span>    llama_logit_bias *logit_bias_array = <span class="keyword">nullptr</span>;</div>
<div class="line"><span class="lineno">  291</span>    <span class="keywordflow">if</span> (sampling &amp;&amp; sampling-&gt;<a class="code hl_variable" href="structgemma__sampling__config.html#a5ab8039031aa1ccde9eefd8708ca5e30">logit_biases</a> &amp;&amp; sampling-&gt;<a class="code hl_variable" href="structgemma__sampling__config.html#aafa252390ecf52cbc6474140a42c7496">num_logit_biases</a> &gt; 0) {</div>
<div class="line"><span class="lineno">  292</span>        <span class="keywordtype">size_t</span> capacity = 0;</div>
<div class="line"><span class="lineno">  293</span>        <span class="keywordflow">for</span> (<span class="keywordtype">size_t</span> i = 0; i &lt; sampling-&gt;<a class="code hl_variable" href="structgemma__sampling__config.html#aafa252390ecf52cbc6474140a42c7496">num_logit_biases</a>; ++i) {</div>
<div class="line"><span class="lineno">  294</span>            <span class="keyword">const</span> <a class="code hl_struct" href="structgemma__logit__bias__entry.html">gemma_logit_bias_entry</a> *entry = &amp;sampling-&gt;<a class="code hl_variable" href="structgemma__sampling__config.html#a5ab8039031aa1ccde9eefd8708ca5e30">logit_biases</a>[i];</div>
<div class="line"><span class="lineno">  295</span>            <span class="keywordflow">if</span> (!entry-&gt;<a class="code hl_variable" href="structgemma__logit__bias__entry.html#a1499e575c452420b1b558300543d8b4e">text</a> || entry-&gt;<a class="code hl_variable" href="structgemma__logit__bias__entry.html#a1499e575c452420b1b558300543d8b4e">text</a>[0] == <span class="charliteral">&#39;\0&#39;</span>) {</div>
<div class="line"><span class="lineno">  296</span>                <span class="keywordflow">continue</span>;</div>
<div class="line"><span class="lineno">  297</span>            }</div>
<div class="line"><span class="lineno">  298</span>            int32_t need = llama_tokenize(vocab,</div>
<div class="line"><span class="lineno">  299</span>                                          entry-&gt;<a class="code hl_variable" href="structgemma__logit__bias__entry.html#a1499e575c452420b1b558300543d8b4e">text</a>,</div>
<div class="line"><span class="lineno">  300</span>                                          (int32_t) std::strlen(entry-&gt;<a class="code hl_variable" href="structgemma__logit__bias__entry.html#a1499e575c452420b1b558300543d8b4e">text</a>),</div>
<div class="line"><span class="lineno">  301</span>                                          <span class="keyword">nullptr</span>,</div>
<div class="line"><span class="lineno">  302</span>                                          0,</div>
<div class="line"><span class="lineno">  303</span>                                          <span class="keyword">true</span>,</div>
<div class="line"><span class="lineno">  304</span>                                          <span class="keyword">true</span>);</div>
<div class="line"><span class="lineno">  305</span>            <span class="keywordflow">if</span> (need &lt; 0) {</div>
<div class="line"><span class="lineno">  306</span>                need = -need;</div>
<div class="line"><span class="lineno">  307</span>            }</div>
<div class="line"><span class="lineno">  308</span>            <span class="keywordflow">if</span> (need &gt; 0) {</div>
<div class="line"><span class="lineno">  309</span>                capacity += (size_t) need;</div>
<div class="line"><span class="lineno">  310</span>            }</div>
<div class="line"><span class="lineno">  311</span>        }</div>
<div class="line"><span class="lineno">  312</span> </div>
<div class="line"><span class="lineno">  313</span>        <span class="keywordflow">if</span> (capacity &gt; 0) {</div>
<div class="line"><span class="lineno">  314</span>            logit_bias_array = (llama_logit_bias *) std::malloc(<span class="keyword">sizeof</span>(llama_logit_bias) * capacity);</div>
<div class="line"><span class="lineno">  315</span>            <span class="keywordflow">if</span> (!logit_bias_array) {</div>
<div class="line"><span class="lineno">  316</span>                copy_error(<span class="stringliteral">&quot;failed to allocate logit bias array&quot;</span>, errbuf, errbuf_size);</div>
<div class="line"><span class="lineno">  317</span>                <span class="keywordflow">return</span> -1;</div>
<div class="line"><span class="lineno">  318</span>            }</div>
<div class="line"><span class="lineno">  319</span> </div>
<div class="line"><span class="lineno">  320</span>            <span class="keywordtype">size_t</span> cursor = 0;</div>
<div class="line"><span class="lineno">  321</span>            <span class="keyword">const</span> llama_token bos_token = llama_vocab_bos(vocab);</div>
<div class="line"><span class="lineno">  322</span>            <span class="keywordflow">for</span> (<span class="keywordtype">size_t</span> i = 0; i &lt; sampling-&gt;<a class="code hl_variable" href="structgemma__sampling__config.html#aafa252390ecf52cbc6474140a42c7496">num_logit_biases</a>; ++i) {</div>
<div class="line"><span class="lineno">  323</span>                <span class="keyword">const</span> <a class="code hl_struct" href="structgemma__logit__bias__entry.html">gemma_logit_bias_entry</a> *entry = &amp;sampling-&gt;<a class="code hl_variable" href="structgemma__sampling__config.html#a5ab8039031aa1ccde9eefd8708ca5e30">logit_biases</a>[i];</div>
<div class="line"><span class="lineno">  324</span>                <span class="keywordflow">if</span> (!entry-&gt;<a class="code hl_variable" href="structgemma__logit__bias__entry.html#a1499e575c452420b1b558300543d8b4e">text</a> || entry-&gt;<a class="code hl_variable" href="structgemma__logit__bias__entry.html#a1499e575c452420b1b558300543d8b4e">text</a>[0] == <span class="charliteral">&#39;\0&#39;</span>) {</div>
<div class="line"><span class="lineno">  325</span>                    <span class="keywordflow">continue</span>;</div>
<div class="line"><span class="lineno">  326</span>                }</div>
<div class="line"><span class="lineno">  327</span>                int32_t need = llama_tokenize(vocab,</div>
<div class="line"><span class="lineno">  328</span>                                              entry-&gt;<a class="code hl_variable" href="structgemma__logit__bias__entry.html#a1499e575c452420b1b558300543d8b4e">text</a>,</div>
<div class="line"><span class="lineno">  329</span>                                              (int32_t) std::strlen(entry-&gt;<a class="code hl_variable" href="structgemma__logit__bias__entry.html#a1499e575c452420b1b558300543d8b4e">text</a>),</div>
<div class="line"><span class="lineno">  330</span>                                              <span class="keyword">nullptr</span>,</div>
<div class="line"><span class="lineno">  331</span>                                              0,</div>
<div class="line"><span class="lineno">  332</span>                                              <span class="keyword">true</span>,</div>
<div class="line"><span class="lineno">  333</span>                                              <span class="keyword">true</span>);</div>
<div class="line"><span class="lineno">  334</span>                <span class="keywordflow">if</span> (need &lt; 0) {</div>
<div class="line"><span class="lineno">  335</span>                    need = -need;</div>
<div class="line"><span class="lineno">  336</span>                }</div>
<div class="line"><span class="lineno">  337</span>                <span class="keywordflow">if</span> (need &lt;= 0) {</div>
<div class="line"><span class="lineno">  338</span>                    <span class="keywordflow">continue</span>;</div>
<div class="line"><span class="lineno">  339</span>                }</div>
<div class="line"><span class="lineno">  340</span> </div>
<div class="line"><span class="lineno">  341</span>                llama_token *tmp_tokens = (llama_token *) std::malloc(<span class="keyword">sizeof</span>(llama_token) * (<span class="keywordtype">size_t</span>) need);</div>
<div class="line"><span class="lineno">  342</span>                <span class="keywordflow">if</span> (!tmp_tokens) {</div>
<div class="line"><span class="lineno">  343</span>                    std::free(logit_bias_array);</div>
<div class="line"><span class="lineno">  344</span>                    copy_error(<span class="stringliteral">&quot;failed to allocate temporary token buffer&quot;</span>, errbuf, errbuf_size);</div>
<div class="line"><span class="lineno">  345</span>                    <span class="keywordflow">return</span> -1;</div>
<div class="line"><span class="lineno">  346</span>                }</div>
<div class="line"><span class="lineno">  347</span> </div>
<div class="line"><span class="lineno">  348</span>                int32_t produced = llama_tokenize(vocab,</div>
<div class="line"><span class="lineno">  349</span>                                                  entry-&gt;<a class="code hl_variable" href="structgemma__logit__bias__entry.html#a1499e575c452420b1b558300543d8b4e">text</a>,</div>
<div class="line"><span class="lineno">  350</span>                                                  (int32_t) std::strlen(entry-&gt;<a class="code hl_variable" href="structgemma__logit__bias__entry.html#a1499e575c452420b1b558300543d8b4e">text</a>),</div>
<div class="line"><span class="lineno">  351</span>                                                  tmp_tokens,</div>
<div class="line"><span class="lineno">  352</span>                                                  need,</div>
<div class="line"><span class="lineno">  353</span>                                                  <span class="keyword">true</span>,</div>
<div class="line"><span class="lineno">  354</span>                                                  <span class="keyword">true</span>);</div>
<div class="line"><span class="lineno">  355</span>                <span class="keywordflow">if</span> (produced &lt; 0) {</div>
<div class="line"><span class="lineno">  356</span>                    produced = -produced;</div>
<div class="line"><span class="lineno">  357</span>                }</div>
<div class="line"><span class="lineno">  358</span> </div>
<div class="line"><span class="lineno">  359</span>                <span class="keywordflow">for</span> (int32_t j = 0; j &lt; produced; ++j) {</div>
<div class="line"><span class="lineno">  360</span>                    <span class="keywordflow">if</span> (tmp_tokens[j] == bos_token) {</div>
<div class="line"><span class="lineno">  361</span>                        <span class="keywordflow">continue</span>;</div>
<div class="line"><span class="lineno">  362</span>                    }</div>
<div class="line"><span class="lineno">  363</span>                    <span class="keywordflow">if</span> (cursor &lt; capacity) {</div>
<div class="line"><span class="lineno">  364</span>                        logit_bias_array[cursor].token = tmp_tokens[j];</div>
<div class="line"><span class="lineno">  365</span>                        logit_bias_array[cursor].bias = entry-&gt;<a class="code hl_variable" href="structgemma__logit__bias__entry.html#a69e6c1f8439637b9e3f8e8ca473166e2">bias</a>;</div>
<div class="line"><span class="lineno">  366</span>                        ++cursor;</div>
<div class="line"><span class="lineno">  367</span>                    }</div>
<div class="line"><span class="lineno">  368</span>                }</div>
<div class="line"><span class="lineno">  369</span>                std::free(tmp_tokens);</div>
<div class="line"><span class="lineno">  370</span> </div>
<div class="line"><span class="lineno">  371</span>                <span class="keywordflow">if</span> (cursor == capacity) {</div>
<div class="line"><span class="lineno">  372</span>                    <span class="keywordflow">break</span>;</div>
<div class="line"><span class="lineno">  373</span>                }</div>
<div class="line"><span class="lineno">  374</span>            }</div>
<div class="line"><span class="lineno">  375</span> </div>
<div class="line"><span class="lineno">  376</span>            <span class="keywordflow">if</span> (cursor &gt; 0) {</div>
<div class="line"><span class="lineno">  377</span>                <span class="keyword">const</span> int32_t n_vocab = llama_vocab_n_tokens(vocab);</div>
<div class="line"><span class="lineno">  378</span>                logit_bias_sampler = llama_sampler_init_logit_bias(n_vocab,</div>
<div class="line"><span class="lineno">  379</span>                                                                   (int32_t) cursor,</div>
<div class="line"><span class="lineno">  380</span>                                                                   logit_bias_array);</div>
<div class="line"><span class="lineno">  381</span>                <span class="keywordflow">if</span> (!logit_bias_sampler) {</div>
<div class="line"><span class="lineno">  382</span>                    std::free(logit_bias_array);</div>
<div class="line"><span class="lineno">  383</span>                    copy_error(<span class="stringliteral">&quot;failed to initialise logit bias sampler&quot;</span>, errbuf, errbuf_size);</div>
<div class="line"><span class="lineno">  384</span>                    <span class="keywordflow">return</span> -1;</div>
<div class="line"><span class="lineno">  385</span>                }</div>
<div class="line"><span class="lineno">  386</span>                llama_sampler_chain_add(sampler, logit_bias_sampler);</div>
<div class="line"><span class="lineno">  387</span>            }</div>
<div class="line"><span class="lineno">  388</span> </div>
<div class="line"><span class="lineno">  389</span>            std::free(logit_bias_array);</div>
<div class="line"><span class="lineno">  390</span>        }</div>
<div class="line"><span class="lineno">  391</span>    }</div>
<div class="line"><span class="lineno">  392</span>    <span class="keywordflow">if</span> (smp.<a class="code hl_variable" href="structgemma__sampling__config.html#a7ca1b736dcf9b3776bef1bc3fc4f05a3">temperature</a> &lt;= 0.0f) {</div>
<div class="line"><span class="lineno">  393</span>        llama_sampler *greedy = llama_sampler_init_greedy();</div>
<div class="line"><span class="lineno">  394</span>        <span class="keywordflow">if</span> (!greedy) {</div>
<div class="line"><span class="lineno">  395</span>            llama_sampler_free(sampler);</div>
<div class="line"><span class="lineno">  396</span>            copy_error(<span class="stringliteral">&quot;failed to initialise greedy sampler&quot;</span>, errbuf, errbuf_size);</div>
<div class="line"><span class="lineno">  397</span>            <span class="keywordflow">return</span> -1;</div>
<div class="line"><span class="lineno">  398</span>        }</div>
<div class="line"><span class="lineno">  399</span>        llama_sampler_chain_add(sampler, greedy);</div>
<div class="line"><span class="lineno">  400</span>    } <span class="keywordflow">else</span> {</div>
<div class="line"><span class="lineno">  401</span>        llama_sampler *temp = llama_sampler_init_temp(smp.<a class="code hl_variable" href="structgemma__sampling__config.html#a7ca1b736dcf9b3776bef1bc3fc4f05a3">temperature</a>);</div>
<div class="line"><span class="lineno">  402</span>        <span class="keywordflow">if</span> (!temp) {</div>
<div class="line"><span class="lineno">  403</span>            llama_sampler_free(sampler);</div>
<div class="line"><span class="lineno">  404</span>            copy_error(<span class="stringliteral">&quot;failed to initialise temperature sampler&quot;</span>, errbuf, errbuf_size);</div>
<div class="line"><span class="lineno">  405</span>            <span class="keywordflow">return</span> -1;</div>
<div class="line"><span class="lineno">  406</span>        }</div>
<div class="line"><span class="lineno">  407</span>        llama_sampler_chain_add(sampler, temp);</div>
<div class="line"><span class="lineno">  408</span> </div>
<div class="line"><span class="lineno">  409</span>        <span class="keyword">const</span> uint32_t sampler_seed = resolve_seed(ctx-&gt;runtime.<a class="code hl_variable" href="structgemma__runtime__config.html#ae469f097c9df4ea415171356ed061d73">seed</a>);</div>
<div class="line"><span class="lineno">  410</span>        llama_sampler *dist = llama_sampler_init_dist(sampler_seed);</div>
<div class="line"><span class="lineno">  411</span>        <span class="keywordflow">if</span> (!dist) {</div>
<div class="line"><span class="lineno">  412</span>            llama_sampler_free(sampler);</div>
<div class="line"><span class="lineno">  413</span>            copy_error(<span class="stringliteral">&quot;failed to initialise distribution sampler&quot;</span>, errbuf, errbuf_size);</div>
<div class="line"><span class="lineno">  414</span>            <span class="keywordflow">return</span> -1;</div>
<div class="line"><span class="lineno">  415</span>        }</div>
<div class="line"><span class="lineno">  416</span>        llama_sampler_chain_add(sampler, dist);</div>
<div class="line"><span class="lineno">  417</span>    }</div>
<div class="line"><span class="lineno">  418</span> </div>
<div class="line"><span class="lineno">  419</span>    llama_sampler_reset(sampler);</div>
<div class="line"><span class="lineno">  420</span> </div>
<div class="line"><span class="lineno">  421</span>    llama_batch batch = llama_batch_get_one(prompt_tokens.data(), <span class="keyword">static_cast&lt;</span>int32_t<span class="keyword">&gt;</span>(prompt_tokens.size()));</div>
<div class="line"><span class="lineno">  422</span> </div>
<div class="line"><span class="lineno">  423</span>    <span class="keywordtype">bool</span> aborted = <span class="keyword">false</span>;</div>
<div class="line"><span class="lineno">  424</span>    llama_token new_token = 0;</div>
<div class="line"><span class="lineno">  425</span>    <span class="keywordtype">bool</span> prompt_history_added = <span class="keyword">false</span>;</div>
<div class="line"><span class="lineno">  426</span> </div>
<div class="line"><span class="lineno">  427</span>    <span class="keywordflow">for</span> (int32_t generated = 0; generated &lt; max_new; ++generated) {</div>
<div class="line"><span class="lineno">  428</span>        <span class="keywordflow">if</span> (llama_decode(ctx-&gt;ctx, batch) != 0) {</div>
<div class="line"><span class="lineno">  429</span>            llama_sampler_free(sampler);</div>
<div class="line"><span class="lineno">  430</span>            copy_error(<span class="stringliteral">&quot;llama_decode failed&quot;</span>, errbuf, errbuf_size);</div>
<div class="line"><span class="lineno">  431</span>            <span class="keywordflow">return</span> -1;</div>
<div class="line"><span class="lineno">  432</span>        }</div>
<div class="line"><span class="lineno">  433</span> </div>
<div class="line"><span class="lineno">  434</span>        <span class="keywordflow">if</span> (!prompt_history_added) {</div>
<div class="line"><span class="lineno">  435</span>            <span class="keywordflow">for</span> (llama_token token : prompt_tokens) {</div>
<div class="line"><span class="lineno">  436</span>                llama_sampler_accept(sampler, token);</div>
<div class="line"><span class="lineno">  437</span>            }</div>
<div class="line"><span class="lineno">  438</span>            prompt_history_added = <span class="keyword">true</span>;</div>
<div class="line"><span class="lineno">  439</span>        }</div>
<div class="line"><span class="lineno">  440</span> </div>
<div class="line"><span class="lineno">  441</span>        llama_token candidate = llama_sampler_sample(sampler, ctx-&gt;ctx, -1);</div>
<div class="line"><span class="lineno">  442</span>        <span class="keywordflow">if</span> (llama_vocab_is_eog(vocab, candidate)) {</div>
<div class="line"><span class="lineno">  443</span>            <span class="keywordflow">break</span>;</div>
<div class="line"><span class="lineno">  444</span>        }</div>
<div class="line"><span class="lineno">  445</span> </div>
<div class="line"><span class="lineno">  446</span>        <span class="keywordtype">char</span> piece[512];</div>
<div class="line"><span class="lineno">  447</span>        <span class="keywordtype">int</span> piece_len = llama_token_to_piece(vocab, candidate, piece, <span class="keyword">sizeof</span>(piece), 0, <span class="keyword">true</span>);</div>
<div class="line"><span class="lineno">  448</span>        <span class="keywordflow">if</span> (piece_len &lt; 0) {</div>
<div class="line"><span class="lineno">  449</span>            llama_sampler_free(sampler);</div>
<div class="line"><span class="lineno">  450</span>            copy_error(<span class="stringliteral">&quot;failed to convert token to text&quot;</span>, errbuf, errbuf_size);</div>
<div class="line"><span class="lineno">  451</span>            <span class="keywordflow">return</span> -1;</div>
<div class="line"><span class="lineno">  452</span>        }</div>
<div class="line"><span class="lineno">  453</span> </div>
<div class="line"><span class="lineno">  454</span>        <span class="keywordflow">if</span> (on_token &amp;&amp; piece_len &gt; 0) {</div>
<div class="line"><span class="lineno">  455</span>            std::string token_text(piece, piece_len);</div>
<div class="line"><span class="lineno">  456</span>            <span class="keywordflow">if</span> (!on_token(token_text.c_str(), user_data)) {</div>
<div class="line"><span class="lineno">  457</span>                aborted = <span class="keyword">true</span>;</div>
<div class="line"><span class="lineno">  458</span>                <span class="keywordflow">break</span>;</div>
<div class="line"><span class="lineno">  459</span>            }</div>
<div class="line"><span class="lineno">  460</span>        }</div>
<div class="line"><span class="lineno">  461</span> </div>
<div class="line"><span class="lineno">  462</span>        llama_sampler_accept(sampler, candidate);</div>
<div class="line"><span class="lineno">  463</span> </div>
<div class="line"><span class="lineno">  464</span>        new_token = candidate;</div>
<div class="line"><span class="lineno">  465</span>        batch = llama_batch_get_one(&amp;new_token, 1);</div>
<div class="line"><span class="lineno">  466</span>    }</div>
<div class="line"><span class="lineno">  467</span> </div>
<div class="line"><span class="lineno">  468</span>    llama_sampler_free(sampler);</div>
<div class="line"><span class="lineno">  469</span> </div>
<div class="line"><span class="lineno">  470</span>    <span class="keywordflow">return</span> aborted ? 1 : 0;</div>
<div class="line"><span class="lineno">  471</span>}</div>
<div class="ttc" id="agemma__llama_8cpp_html_ad945475f5fbb0fc612be2cb3de0e3076"><div class="ttname"><a href="gemma__llama_8cpp.html#ad945475f5fbb0fc612be2cb3de0e3076">gemma_default_sampling</a></div><div class="ttdeci">void gemma_default_sampling(gemma_sampling_config *cfg)</div><div class="ttdef"><b>Definition</b> <a href="gemma__llama_8cpp_source.html#l00078">gemma_llama.cpp:78</a></div></div>
<div class="ttc" id="astructgemma__logit__bias__entry_html"><div class="ttname"><a href="structgemma__logit__bias__entry.html">gemma_logit_bias_entry</a></div><div class="ttdef"><b>Definition</b> <a href="gemma__llama_8h_source.html#l00040">gemma_llama.h:40</a></div></div>
<div class="ttc" id="astructgemma__logit__bias__entry_html_a1499e575c452420b1b558300543d8b4e"><div class="ttname"><a href="structgemma__logit__bias__entry.html#a1499e575c452420b1b558300543d8b4e">gemma_logit_bias_entry::text</a></div><div class="ttdeci">const char * text</div><div class="ttdef"><b>Definition</b> <a href="gemma__llama_8h_source.html#l00041">gemma_llama.h:41</a></div></div>
<div class="ttc" id="astructgemma__logit__bias__entry_html_a69e6c1f8439637b9e3f8e8ca473166e2"><div class="ttname"><a href="structgemma__logit__bias__entry.html#a69e6c1f8439637b9e3f8e8ca473166e2">gemma_logit_bias_entry::bias</a></div><div class="ttdeci">float bias</div><div class="ttdef"><b>Definition</b> <a href="gemma__llama_8h_source.html#l00042">gemma_llama.h:42</a></div></div>
<div class="ttc" id="astructgemma__sampling__config_html"><div class="ttname"><a href="structgemma__sampling__config.html">gemma_sampling_config</a></div><div class="ttdef"><b>Definition</b> <a href="gemma__llama_8h_source.html#l00048">gemma_llama.h:48</a></div></div>
</div><!-- fragment -->
<p class="reference">References <a class="el" href="gemma__llama_8h_source.html#l00042">gemma_logit_bias_entry::bias</a>, <a class="el" href="gemma__llama_8h_source.html#l00055">gemma_sampling_config::frequency_penalty</a>, <a class="el" href="gemma__llama_8cpp_source.html#l00078">gemma_default_sampling()</a>, <a class="el" href="gemma__llama_8h_source.html#l00059">gemma_sampling_config::logit_biases</a>, <a class="el" href="gemma__llama_8h_source.html#l00049">gemma_sampling_config::max_new_tokens</a>, <a class="el" href="gemma__llama_8h_source.html#l00057">gemma_sampling_config::min_p</a>, <a class="el" href="gemma__llama_8h_source.html#l00060">gemma_sampling_config::num_logit_biases</a>, <a class="el" href="gemma__llama_8h_source.html#l00056">gemma_sampling_config::presence_penalty</a>, <a class="el" href="gemma__llama_8h_source.html#l00054">gemma_sampling_config::repetition_last_n</a>, <a class="el" href="gemma__llama_8h_source.html#l00053">gemma_sampling_config::repetition_penalty</a>, <a class="el" href="gemma__llama_8h_source.html#l00031">gemma_runtime_config::seed</a>, <a class="el" href="gemma__llama_8h_source.html#l00050">gemma_sampling_config::temperature</a>, <a class="el" href="gemma__llama_8h_source.html#l00041">gemma_logit_bias_entry::text</a>, <a class="el" href="gemma__llama_8h_source.html#l00052">gemma_sampling_config::top_k</a>, <a class="el" href="gemma__llama_8h_source.html#l00051">gemma_sampling_config::top_p</a>, and <a class="el" href="gemma__llama_8h_source.html#l00058">gemma_sampling_config::typical_p</a>.</p>

<p class="reference">Referenced by <a class="el" href="gemma__cli_8c_source.html#l00041">main()</a>.</p>
<div id="dynsection-5" onclick="return dynsection.toggleVisibility(this)" class="dynheader closed" style="cursor:pointer;"><span class="dynarrow"><span class="arrowhead closed"></span></span>Here is the call graph for this function:</div>
<div id="dynsection-5-summary" class="dynsummary" style="display:block;">
</div>
<div id="dynsection-5-content" class="dyncontent" style="display:none;">
<div class="center"><iframe scrolling="no" loading="lazy" frameborder="0" src="gemma__llama_8h_aa4cc4ad3d0c07b4bd23d397039b9df21_cgraph.svg" width="388" height="36"><p><b>This browser is not able to show SVG: try Firefox, Chrome, Safari, or Opera instead.</b></p></iframe></div>
</div>
<div id="dynsection-6" onclick="return dynsection.toggleVisibility(this)" class="dynheader closed" style="cursor:pointer;"><span class="dynarrow"><span class="arrowhead closed"></span></span>Here is the caller graph for this function:</div>
<div id="dynsection-6-summary" class="dynsummary" style="display:block;">
</div>
<div id="dynsection-6-content" class="dyncontent" style="display:none;">
<div class="center"><iframe scrolling="no" loading="lazy" frameborder="0" src="gemma__llama_8h_aa4cc4ad3d0c07b4bd23d397039b9df21_icgraph.svg" width="268" height="36"><p><b>This browser is not able to show SVG: try Firefox, Chrome, Safari, or Opera instead.</b></p></iframe></div>
</div>

</div>
</div>
<a id="a729e876bef94b34d08d69d800ff52b59" name="a729e876bef94b34d08d69d800ff52b59"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a729e876bef94b34d08d69d800ff52b59">&#9670;&#160;</a></span>gemma_llama_init()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">int gemma_llama_init </td>
          <td>(</td>
          <td class="paramtype">const char *</td>          <td class="paramname"><span class="paramname"><em>model_path</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="structgemma__runtime__config.html">gemma_runtime_config</a> *</td>          <td class="paramname"><span class="paramname"><em>runtime</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="#a52d64edda44be4ce464fd2b0ac4fccd0">gemma_llama_t</a> **</td>          <td class="paramname"><span class="paramname"><em>out_ctx</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">char *</td>          <td class="paramname"><span class="paramname"><em>errbuf</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">size_t</td>          <td class="paramname"><span class="paramname"><em>errbuf_size</em></span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">
<p>Loads a Gemma 3 4B instruction-tuned model in GGUF format using llama.cpp.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">model_path</td><td>Path to the GGUF weights (convert via convert-hf-to-gguf.py). </td></tr>
    <tr><td class="paramname">runtime</td><td>Optional runtime config; pass NULL for defaults. </td></tr>
    <tr><td class="paramname">out_ctx</td><td>Receives the initialized context on success. </td></tr>
    <tr><td class="paramname">errbuf</td><td>Optional user buffer to inspect errors. </td></tr>
    <tr><td class="paramname">errbuf_size</td><td>Size of errbuf in bytes. </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>0 on success, negative value on failure. </dd></dl>

<p class="definition">Definition at line <a class="el" href="gemma__llama_8cpp_source.html#l00096">96</a> of file <a class="el" href="gemma__llama_8cpp_source.html">gemma_llama.cpp</a>.</p>
<div class="fragment"><div class="line"><span class="lineno">  100</span>                                         {</div>
<div class="line"><span class="lineno">  101</span>    <span class="keywordflow">if</span> (!out_ctx) {</div>
<div class="line"><span class="lineno">  102</span>        copy_error(<span class="stringliteral">&quot;out_ctx is null&quot;</span>, errbuf, errbuf_size);</div>
<div class="line"><span class="lineno">  103</span>        <span class="keywordflow">return</span> -1;</div>
<div class="line"><span class="lineno">  104</span>    }</div>
<div class="line"><span class="lineno">  105</span>    *out_ctx = <span class="keyword">nullptr</span>;</div>
<div class="line"><span class="lineno">  106</span> </div>
<div class="line"><span class="lineno">  107</span>    <span class="keywordflow">if</span> (!model_path || std::strlen(model_path) == 0) {</div>
<div class="line"><span class="lineno">  108</span>        copy_error(<span class="stringliteral">&quot;model_path is empty&quot;</span>, errbuf, errbuf_size);</div>
<div class="line"><span class="lineno">  109</span>        <span class="keywordflow">return</span> -1;</div>
<div class="line"><span class="lineno">  110</span>    }</div>
<div class="line"><span class="lineno">  111</span> </div>
<div class="line"><span class="lineno">  112</span>    <a class="code hl_struct" href="structgemma__runtime__config.html">gemma_runtime_config</a> rt;</div>
<div class="line"><span class="lineno">  113</span>    <a class="code hl_function" href="gemma__llama_8cpp.html#aaf1f19f3f121e97040c5fbc9e6d055c6">gemma_default_runtime</a>(&amp;rt);</div>
<div class="line"><span class="lineno">  114</span>    <span class="keywordflow">if</span> (runtime) {</div>
<div class="line"><span class="lineno">  115</span>        rt = *runtime;</div>
<div class="line"><span class="lineno">  116</span>    }</div>
<div class="line"><span class="lineno">  117</span> </div>
<div class="line"><span class="lineno">  118</span>    backend_init_once(rt.<a class="code hl_variable" href="structgemma__runtime__config.html#ac3b23f6413b7f41772f3e537cbc6feb4">numa</a> &gt; 0);</div>
<div class="line"><span class="lineno">  119</span> </div>
<div class="line"><span class="lineno">  120</span>    llama_model_params mparams = llama_model_default_params();</div>
<div class="line"><span class="lineno">  121</span>    mparams.n_gpu_layers = rt.<a class="code hl_variable" href="structgemma__runtime__config.html#ad780f2352af8763ba51a4d453ad8888d">n_gpu_layers</a>;</div>
<div class="line"><span class="lineno">  122</span>    mparams.main_gpu = rt.<a class="code hl_variable" href="structgemma__runtime__config.html#af8ab449279a04b88c0b36001ad4ab600">main_gpu</a>;</div>
<div class="line"><span class="lineno">  123</span>    mparams.split_mode = <span class="keyword">static_cast&lt;</span>llama_split_mode<span class="keyword">&gt;</span>(rt.<a class="code hl_variable" href="structgemma__runtime__config.html#af97928a8d4ca4c3354544f4635783485">split_mode</a>);</div>
<div class="line"><span class="lineno">  124</span>    mparams.progress_callback = <span class="keyword">nullptr</span>;</div>
<div class="line"><span class="lineno">  125</span>    mparams.use_mmap = rt.<a class="code hl_variable" href="structgemma__runtime__config.html#a7c1c013524220fd9e1efe779191bf3d6">use_mmap</a> != 0;</div>
<div class="line"><span class="lineno">  126</span>    mparams.use_mlock = rt.<a class="code hl_variable" href="structgemma__runtime__config.html#a98e546bacc64cfa58eab2f49975008d0">use_mlock</a> != 0;</div>
<div class="line"><span class="lineno">  127</span>    mparams.check_tensors = <span class="keyword">false</span>; <span class="comment">// skip tensor checks for performance</span></div>
<div class="line"><span class="lineno">  128</span> </div>
<div class="line"><span class="lineno">  129</span>    llama_model *model = llama_model_load_from_file(model_path, mparams);</div>
<div class="line"><span class="lineno">  130</span>    <span class="keywordflow">if</span> (!model) {</div>
<div class="line"><span class="lineno">  131</span>        copy_error(<span class="stringliteral">&quot;failed to load GGUF model&quot;</span>, errbuf, errbuf_size);</div>
<div class="line"><span class="lineno">  132</span>        <span class="keywordflow">return</span> -1;</div>
<div class="line"><span class="lineno">  133</span>    }</div>
<div class="line"><span class="lineno">  134</span> </div>
<div class="line"><span class="lineno">  135</span>    llama_context_params cparams = llama_context_default_params();</div>
<div class="line"><span class="lineno">  136</span>    cparams.offload_kqv = <span class="keyword">true</span>; <span class="comment">// offload KV cache to GPU</span></div>
<div class="line"><span class="lineno">  137</span>    cparams.n_ubatch = (rt.<a class="code hl_variable" href="structgemma__runtime__config.html#a44621855cb58b453984079384606993e">n_batch</a> &gt; 0 ? rt.<a class="code hl_variable" href="structgemma__runtime__config.html#a44621855cb58b453984079384606993e">n_batch</a> : 512); <span class="comment">// physical batch size</span></div>
<div class="line"><span class="lineno">  138</span> </div>
<div class="line"><span class="lineno">  139</span>    <span class="keywordflow">if</span> (rt.<a class="code hl_variable" href="structgemma__runtime__config.html#a66e18c45bf39a21e5d7ce4a47cf3e4ba">n_ctx</a> &gt; 0) {</div>
<div class="line"><span class="lineno">  140</span>        cparams.n_ctx = rt.<a class="code hl_variable" href="structgemma__runtime__config.html#a66e18c45bf39a21e5d7ce4a47cf3e4ba">n_ctx</a>;</div>
<div class="line"><span class="lineno">  141</span>    }</div>
<div class="line"><span class="lineno">  142</span>    <span class="keywordflow">if</span> (rt.<a class="code hl_variable" href="structgemma__runtime__config.html#a44621855cb58b453984079384606993e">n_batch</a> &gt; 0) {</div>
<div class="line"><span class="lineno">  143</span>        cparams.n_batch = rt.<a class="code hl_variable" href="structgemma__runtime__config.html#a44621855cb58b453984079384606993e">n_batch</a>;</div>
<div class="line"><span class="lineno">  144</span>    }</div>
<div class="line"><span class="lineno">  145</span>    <span class="keywordflow">if</span> (rt.<a class="code hl_variable" href="structgemma__runtime__config.html#ac8ef05e79800d7ed488399f6e56915c3">n_threads</a> &gt; 0) {</div>
<div class="line"><span class="lineno">  146</span>        cparams.n_threads = rt.<a class="code hl_variable" href="structgemma__runtime__config.html#ac8ef05e79800d7ed488399f6e56915c3">n_threads</a>;</div>
<div class="line"><span class="lineno">  147</span>        cparams.n_threads_batch = rt.<a class="code hl_variable" href="structgemma__runtime__config.html#ac8ef05e79800d7ed488399f6e56915c3">n_threads</a>;</div>
<div class="line"><span class="lineno">  148</span>    }</div>
<div class="line"><span class="lineno">  149</span> </div>
<div class="line"><span class="lineno">  150</span>    llama_context *ctx = llama_init_from_model(model, cparams);</div>
<div class="line"><span class="lineno">  151</span>    <span class="keywordflow">if</span> (!ctx) {</div>
<div class="line"><span class="lineno">  152</span>        llama_model_free(model);</div>
<div class="line"><span class="lineno">  153</span>        copy_error(<span class="stringliteral">&quot;failed to create llama context&quot;</span>, errbuf, errbuf_size);</div>
<div class="line"><span class="lineno">  154</span>        <span class="keywordflow">return</span> -1;</div>
<div class="line"><span class="lineno">  155</span>    }</div>
<div class="line"><span class="lineno">  156</span> </div>
<div class="line"><span class="lineno">  157</span>    <span class="keyword">auto</span> *handle = <span class="keyword">new</span> (std::nothrow) gemma_llama_context();</div>
<div class="line"><span class="lineno">  158</span>    <span class="keywordflow">if</span> (!handle) {</div>
<div class="line"><span class="lineno">  159</span>        llama_free(ctx);</div>
<div class="line"><span class="lineno">  160</span>        llama_model_free(model);</div>
<div class="line"><span class="lineno">  161</span>        copy_error(<span class="stringliteral">&quot;failed to allocate context&quot;</span>, errbuf, errbuf_size);</div>
<div class="line"><span class="lineno">  162</span>        <span class="keywordflow">return</span> -1;</div>
<div class="line"><span class="lineno">  163</span>    }</div>
<div class="line"><span class="lineno">  164</span>    handle-&gt;model = model;</div>
<div class="line"><span class="lineno">  165</span>    handle-&gt;ctx = ctx;</div>
<div class="line"><span class="lineno">  166</span>    handle-&gt;runtime = rt;</div>
<div class="line"><span class="lineno">  167</span> </div>
<div class="line"><span class="lineno">  168</span>    g_active_contexts.fetch_add(1, std::memory_order_relaxed);</div>
<div class="line"><span class="lineno">  169</span>    *out_ctx = handle;</div>
<div class="line"><span class="lineno">  170</span>    <span class="keywordflow">return</span> 0;</div>
<div class="line"><span class="lineno">  171</span>}</div>
<div class="ttc" id="agemma__llama_8cpp_html_aaf1f19f3f121e97040c5fbc9e6d055c6"><div class="ttname"><a href="gemma__llama_8cpp.html#aaf1f19f3f121e97040c5fbc9e6d055c6">gemma_default_runtime</a></div><div class="ttdeci">void gemma_default_runtime(gemma_runtime_config *cfg)</div><div class="ttdef"><b>Definition</b> <a href="gemma__llama_8cpp_source.html#l00062">gemma_llama.cpp:62</a></div></div>
<div class="ttc" id="astructgemma__runtime__config_html"><div class="ttname"><a href="structgemma__runtime__config.html">gemma_runtime_config</a></div><div class="ttdef"><b>Definition</b> <a href="gemma__llama_8h_source.html#l00026">gemma_llama.h:26</a></div></div>
</div><!-- fragment -->
<p class="reference">References <a class="el" href="gemma__llama_8cpp_source.html#l00062">gemma_default_runtime()</a>, <a class="el" href="gemma__llama_8h_source.html#l00032">gemma_runtime_config::main_gpu</a>, <a class="el" href="gemma__llama_8h_source.html#l00028">gemma_runtime_config::n_batch</a>, <a class="el" href="gemma__llama_8h_source.html#l00027">gemma_runtime_config::n_ctx</a>, <a class="el" href="gemma__llama_8h_source.html#l00030">gemma_runtime_config::n_gpu_layers</a>, <a class="el" href="gemma__llama_8h_source.html#l00029">gemma_runtime_config::n_threads</a>, <a class="el" href="gemma__llama_8h_source.html#l00036">gemma_runtime_config::numa</a>, <a class="el" href="gemma__llama_8h_source.html#l00033">gemma_runtime_config::split_mode</a>, <a class="el" href="gemma__llama_8h_source.html#l00035">gemma_runtime_config::use_mlock</a>, and <a class="el" href="gemma__llama_8h_source.html#l00034">gemma_runtime_config::use_mmap</a>.</p>

<p class="reference">Referenced by <a class="el" href="gemma__cli_8c_source.html#l00041">main()</a>.</p>
<div id="dynsection-7" onclick="return dynsection.toggleVisibility(this)" class="dynheader closed" style="cursor:pointer;"><span class="dynarrow"><span class="arrowhead closed"></span></span>Here is the call graph for this function:</div>
<div id="dynsection-7-summary" class="dynsummary" style="display:block;">
</div>
<div id="dynsection-7-content" class="dyncontent" style="display:none;">
<div class="center"><iframe scrolling="no" loading="lazy" frameborder="0" src="gemma__llama_8h_a729e876bef94b34d08d69d800ff52b59_cgraph.svg" width="346" height="36"><p><b>This browser is not able to show SVG: try Firefox, Chrome, Safari, or Opera instead.</b></p></iframe></div>
</div>
<div id="dynsection-8" onclick="return dynsection.toggleVisibility(this)" class="dynheader closed" style="cursor:pointer;"><span class="dynarrow"><span class="arrowhead closed"></span></span>Here is the caller graph for this function:</div>
<div id="dynsection-8-summary" class="dynsummary" style="display:block;">
</div>
<div id="dynsection-8-content" class="dyncontent" style="display:none;">
<div class="center"><iframe scrolling="no" loading="lazy" frameborder="0" src="gemma__llama_8h_a729e876bef94b34d08d69d800ff52b59_icgraph.svg" width="235" height="36"><p><b>This browser is not able to show SVG: try Firefox, Chrome, Safari, or Opera instead.</b></p></iframe></div>
</div>

</div>
</div>
</div><!-- contents -->
</div><!-- doc-content -->
<div id="page-nav" class="page-nav-panel">
<div id="page-nav-resize-handle"></div>
<div id="page-nav-tree">
<div id="page-nav-contents">
</div><!-- page-nav-contents -->
</div><!-- page-nav-tree -->
</div><!-- page-nav -->
</div><!-- container -->
<!-- start footer part -->
<div id="nav-path" class="navpath"><!-- id is needed for treeview function! -->
  <ul>
    <li class="navelem"><a href="dir_d44c64559bbebec7f509842c48db8b23.html">include</a></li><li class="navelem"><a href="gemma__llama_8h.html">gemma_llama.h</a></li>
    <li class="footer">Generated by <a href="https://www.doxygen.org/index.html"><img class="footer" src="doxygen.svg" width="104" height="31" alt="doxygen"/></a> 1.14.0 </li>
  </ul>
</div>
</body>
</html>
